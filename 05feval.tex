
\section{Formative Evaluation}
\label{sec:formative-evaluation}

During Phase C of the project (January 2011 – May 2011, see Section
3), formative evaluation of the ST, CD and GA tools was undertaken
with respect to the usage scenarios identified from Phase B (the usage
scenarios are listed in Section 3.1). This evaluation comprised two
parts.

The first part was a 3-hour evaluation session undertaken with 26
trainee maths teachers on the Postgraduate Certificate in Education
programme at the Institute of Education in London, split into two
parallel groups of 13 for logistical reasons. Each of the participants
had an installation of the MiGen system running on their computer. In
the first half of the session, participants were introduced to the
MiGen project, the MiGen system as a whole, and the eXpresser
tool. Participants were then asked to work through several
construction examples using the eXpresser so as to gain familiarity
with how students might use it in a lesson and the kinds of feedback
the system would give to students. There was then a 15 minute
break. In the following 30 minutes, each of the TA tools was
introduced to the participants, using real data drawn from one of the
classroom trials undertaken in Phase B of the project. In particular,
using the time-stop functionality, the research team “froze” the
display of the data to a time 10 minutes into the lesson and explained
to participants what could be seen from each tool (these displays are
shown in Figures 2, 3 and 5 in Section 2). For the last hour of the
session, participants were asked to move the display of the TA tools
on their computer forwards, firstly to 30 minutes into the lesson, and
then to 5 minutes before the end of the lesson. For each of these two
time-points, participants were asked to complete a short questionnaire
containing questions relating to usage scenarios US1-US6 – the
questionnaire is listed in Appendix 1. At the end of the session,
participants were asked to complete an end-of-session questionnaire –
also listed in Appendix 1 – relating to the full set of usage
scenarios US1-US8. Two participants never completed this questionnaire
so in the results below we refer to 24 students. The aim of these
questionnaires was to elicit feedback relating to the extent to which
the TA tools met the requirements of the usage scenarios.   
 
We summarise below their answers with respect to each of the usage scenarios.

US 1. Finding out which students need the teacher’s immediate help
 
For both time points (“30 mins before the lesson” and “5 minutes prior
to the end”) most teachers (23/26) answered that they would use the
Class Dynamics tool and look for pupils with red circles. The main
difference between the two scenarios was the level of intervention as
most of the comments related to 30 minutes were about just “keeping an
eye” to certain students who did not seem to have a good start and
ensuring that pupils “marked with an amber are staying focused”
whereas towards the end of the lesson providing help seemed more
critical. 2 responses went beyond using the CD tools and recognised
that “GA also shows levels of progress” and can be used also for
deciding which student needs help. 2 teachers mentioned explicitly the
functionality of clicking on the circles to see what the students have
done and if they are behind group them to help them all together. 
 
With regards to finding out which students need immediate help without
the use of the TA tools, 14 out of 24 teachers answered that they
would use a ‘traditional classroom solution’ e.g. ‘walk around the
classroom viewing students’ work and helping any student who may be
off task or needing help” or “students would have to put their hand up
for my immediate attention”. 8 out of 24 came up with more innovative
solutions like ‘traffic lights’ cards to allow students to indicate if
they are doing well (green card) or might be in trouble soon (orange
card) or definitely need help (red card), cups or even a remote
control that would allow students to ‘call the teacher’. 2 teachers
did not answer at all.

In relation to doing the same task with the tools, 10 out of the 24
demonstrated a deep appreciation of the tools stating that they would
use a combination of the tools starting from the CD tool but also
giving elaborate comments such as “visual review of everyone’s status
helps you really check if students are understanding, without asking
each of them individually”, “allows much faster response to students’
queries” or “It clearly highlights who is active and who isn’t”, “it
also shows what they have been doing which helps as sometimes,
although the student is active, they may not be on task” showing that
beyond the obvious answer of relying on the visualisation of the CD
tool the combination of the tools can provide much more elaborate
information to help decision making. 8 out of 24 provided
straightforward answers such as “simple monitoring such as Class
Dynamics and Goal Achievement give a quick overview” still often
demonstrating that they appreciate the potential of combining
information from different tools. 4 teachers did not answer clearly
but 2 provided simple UI suggestions with the main one (also mentioned
from other teachers especially when providing verbal feedback) being
the suggestion for using the colours in the CD tool to also indicate
goal achievement as additional information that could help in
prioritizing which students need help. 
 
US2. Finding out which students are progressing satisfactorily towards completing the task and which ones may be in difficulty.
 
For this usage scenario, with respect to the 30 minutes into the
lesson situation most teachers (19 out of 26) referred explicitly to
the GA tool e.g. “Students who have yet to achieve any goals are in
difficulty” or a combination of GA tool with CD and ST tools. 5
teachers mentioned only the CD tool as a means of finding out in a
glance which students are progressing (since it provides information
about the number of goals achieved at any given time) and 2 would look
for more detailed information at the ST tool. For the scenario 5
minutes prior to the end most teachers referred to their previous
answer or did not provide an answer. 2 of the 5 teachers who answered
said that they would use the CD tool and 1 mentioned commented that it
would be useful to have the ability to see this information per task
according to predefined expectations that they may have. 
 
With regards to the “end of session questionnaire”, 23 out of 24
teachers recognised again that without the TA tools, they would have
to use again a traditional classroom approach such as “Periodically
ask whole class re stage of progress, level of understanding, Plus
constantly circulate to observe them at work and assist as
required”. 2 of these answers contained a comment about the effort
this would require. One teacher came up with some more innovative
approach: “I could get the pupils to personally fill in a tick box of
how they have progressed, though this would take extra time and
effort.” showing again the difficulty in achieving this in any other
way. In relation to doing the same task with the tools, 13 students
seemed to appreciate how the “tools give you [..] a ‘screenshot’ of
what they have produced.”

US3: Finding out which students are currently disengaged from the task.

For both the “30 minutes” and “5 minutes prior to the end” scenarios
teachers appreciated that they would look for circles coloured amber
and provided answers such as “I would be most concered about amber
students who had yet to achieve any tasks”. Again the difference
between the two scenarios was the level of intervention the would take
as some of them recognises that towards the end of the lesson students
could be disengaged because they have finished with the task and
therefore one approach could be to get “those who have finished to
help those who are still struggling”. Their comments rotated around
their need to be able to configure the timing of disengagement
(something that we introduced later through configuration options) and
ideas for providing more information including the type of
disengagement as it is different to, for example, have the expresser
open and perhaps thinking or discussing with their peers than having
the expresser minimised and being disengaged playing a game or
browsing the internet. They commented therefore that they would have
to observe the class as well and some of them --- both in the
questionnaire and in further verbal feedback they have provided ---
wondered whether it would be possible to show their screens. As there
is relevant software that can achieve this we have not focused on such
a usage scenario but instead feel that the disengagement information
provided by the tool is a first sign for doing exactly as the
participants mentioned, walk around the class and observe who is
disengaged or help them choose which screens to see using additional
software. 



As far as the “end of session questionnaire”, 22/24 participants
answered that without the tools they would use again some traditional
classroom solution e.g. “Periodically ask whole class re stage of
progress, level of understanding, Plus general observation… and
constantly circulate to observe them at work and assist as
required..“. 3 of them commented on the difficulty of this
e.g.“Difficult to keep an eye on all pupils, especially when you are
helping one pupil in particular. Pupils often see you coming and
switch back to task as you approach”. In contrast, 15/24 participants
provided answers that demonstrated their appreciation of the tools in
overcoming these difficulties e.g. “The tools give you a clear
indication of who is currently inactive or has stopped working on
their task for over a minute. This gives you a clear indication of who
might be switching off”. 5/24 provided more elaborate comments
demonstrating that an appreciation also of the transformative nature
of the information provided: “The tools provide a way of helping to
increase the efficiency of my role as a teacher. By enabling me to
look at the student tracking tools and the goal achievement tools I
can readily identify those pupils that appear to be disengaged and
subsequently target them for additional support/ encouragement.” 4
participants did not answer but provided UI and other comments. Most
related to the fact that the disengagement information can be
misleading e.g. “Might highlight pupils who are just having a break to
think [or taking notes]. Also some pupils might be active but just
making up patterns on the program i.e. not sticking to task.” or that
students tend to ‘game the system’ as they can “figure out how to
avoid amber by moving the mouse or dragging and dropping every n
minutes”.   

US4: Identifying common conceptual and procedural difficulties
students are facing in order to provide more explanation to the class
as a whole.  

With respect to this usage scenario we asked on purpose “Would this be
a time-point that you would give more explanation to the class as a
whole? And if so what would you say based on information from the
tools?” for the two time points to see how the participants would use
the tools. From the 17 students who answered this question, 9 referred
to the GA tool and to the white squares that show lack of achievement
of some students compared to the rest of the class, whereas 4 would
rely on the student tracking tool but commented on its complexity
during classroom (another 2 mentioned the CD tool but without any
explanation and 2 did not explain why they would address the whole
class but rather said that they would re-cap and perhaps ask for one
of the students to demonstrate their solution).  Once again, the
difference between the two scenarios was the level of their
intervention i.e. in “30 minutes” within the lesson answers seemed to
be around making sure students are progressing whereas in “5 minutes
prior to the end” teachers were concerned with ensuring that students
have achieved important objectives (e.g. creating expressions) and to
wrap up the lesson . Apart from commenting on the complexity of the ST
tool, other UI improvements involved the scrolling needed for goal
achievement.

For both the “30 minutes” and “5 minutes prior to the end” scenarios
teachers appreciated that they would look for circles coloured amber
and provided answers such as “I would be most concerned about amber
students who had yet to achieve any tasks”. Again the difference
between the two scenarios was the level of intervention the would take
as some of them recognises that towards the end of the lesson students
could be disengaged because they have finished with the task and
therefore one approach could be to get “those who have finished to
help those who are still struggling”. Their comments rotated around
their need to be able to configure the timing of disengagement
(something that we introduced later through configuration options) and
ideas for providing more information including the type of
disengagement as it is different to, for example, have the expresser
open and perhaps thinking or discussing with their peers than having
the expresser minimised and being disengaged playing a game or
browsing the internet. They commented therefore that they would have
to observe the class as well and some of them --- both in the
questionnaire and in further verbal feedback they have provided ---
wondered whether it would be possible to show their screens. As there
is relevant software that can achieve this we have not focused on such
a usage scenario but instead feel that the disengagement information
provided by the tool is a first sign for doing exactly as the
participants mentioned, walk around the class and observe who is
disengaged or help them choose which screens to see using additional
software. 

As far as the “end of session questionnaire” was concerned, 22 out of
the 24 participants answered that without the tools they would use
again some traditional classroom solution e.g. “Periodically ask whole
class re stage of progress, level of understanding, Plus general
observation… and constantly circulate to observe them at work and
assist as required..“. 3 of them commented on the difficulty of this,
e.g.“Difficult to keep an eye on all pupils, especially when you are
helping one pupil in particular. Pupils often see you coming and
switch back to task as you approach”. In contrast, 15 out of the 24
participants provided answers that demonstrated their appreciation of
the tools in overcoming these difficulties e.g. “The tools give you a
clear indication of who is currently inactive or has stopped working
on their task for over a minute. This gives you a clear indication of
who might be switching off”. 5 out of the 24 provided more elaborate
comments demonstrating that an appreciation also of the transformative
nature of the information provided: “The tools provide a way of
helping to increase the efficiency of my role as a teacher. By
enabling me to look at the student tracking tools and the goal
achievement tools I can readily identify those pupils that appear to
be disengaged and subsequently target them for additional support/
encouragement.” 4 participants did not answer but provided UI and
other comments. Most related to the fact that the disengagement
information can be misleading e.g. “Might highlight pupils who are
just having a break to think [or taking notes]. Also some pupils might
be active but just making up patterns on the program i.e. not sticking
to task.” or that students tend to ‘game the system’ as they can “figure out how to avoid amber by moving the mouse or dragging and dropping every n minutes”.  

US4: Identifying common conceptual and procedural difficulties
students are facing in order to provide more explanation to the class
as a whole. 

With respect to this usage scenario we asked on purpose “Would this be
a time-point that you would give more explanation to the class as a
whole? And if so what would you say based on information from the
tools?” for the two time points to see how the participants would use
the tools. From the 17 students who answered this question, 9 referred
to the GA tool and to the white squares that show lack of achievement
of some students compared to the rest of the class, whereas 4 would
rely on the student tracking tool but commented on its complexity
during lessons (another 2 mentioned the CD tool but without any
explanation and 2 did not explain why they would address the whole
class but rather said that they would re-cap and perhaps ask for one
of the students to demonstrate their solution).  Once again, the
difference between the two scenarios was the level of their
intervention i.e. in “30 minutes” within the lesson answers seemed to
be around making sure students are progressing whereas in “5 minutes
prior to the end” teachers were concerned with ensuring that students
have achieved important objectives (e.g. creating expressions) and to
wrap up the lesson. Apart from commenting on the complexity of the ST
tool, other UI improvements involved the scrolling needed for goal
achievement. 

US5: Finding out which students have finished the task

For this usage scenario we asked the participants to provide examples
of students who have finished the task and to provide any comments
they may have. 21 out of the 26 participants who replied to this
question (for both time points) provided correct answers
(i.e. indicated students who have finished the tasks). 13 relied on
information of the CD tool (i.e. the number of goal annotation below
the circles) and the rest on the GA tool. There were not many
additional comments apart from 5 participants commenting on the ease
with which they would check which students have finished the task. One
participant said that close to the end of the class, they would
consider displaying GA information available to the interactive
whiteboard for all the students to see and encourage the ones that are
behind to catch up. With respect to what they would have done without
the tools all participants acknowledge that they would have to revert
to some traditional approach whereby they would ask students who have
finished their task to raise their hands.  

15 out of the 24 answered the related questions in the “end of session
questionnaire”. They  provided answers that demonstrated their
appreciation of the tools. 3/24 participants even provided additional
ideas on how they would take advantage of the GA tool. In particular,
according to their comments, it could help them identify difficult
tasks that they may need to modify or allow them to choose which
students to give extension tasks to. With respect to limitations, the
main requests were for the tool to  take into account “the number of
activities a student has gone through” (probably meaning in a
particular session in order to weight the information provided) and
that students who have completed their task are also somehow displayed
in the CD tool to allow for quick identification and action on behalf
of the teacher (e.g. to be given extension work or to help other
students) 

US6: Finding out which students have achieved which task goals.

The results from this question were very similar to the US5
above. Many students replied “see above”, commented on the intuitive
and simple usage of the GA tool. The only comment worth reporting from
the “end of session questionnaire” was one participant’s confusion
about the three degrees of achievement (i.e. the fact that a goal can
be retracted).  

US7: Providing appropriate support and guidance to individual students
(i) during the lesson, and (ii) after the lesson. 

This is a more open-ended use case which can be undertaken during the
lesson using a combination of the tools as described for US1, US2, U3
above, and after the lesson by using the GA tool to see which task
goals an individual student has not managed to achieve, the CD tool to
view the student’s final model and rule as produced by the end of the
lesson, and the ST tool to view the student’s detailed history of
interactions during the lesson. 


--- CONTINUING WITH THE REST OF THE USAGE SCENARIOS/QUESTIONS  --

Apart from the questionnaires, we also collected teachers’ verbal
feedback and comments during the session. Some of the most important
aspects they mentioned regarding the CD tool include recognising the
value of this tool during lessons compared to the other two tools as
it gave them an instant overview of the whole class’s progress. Some
of them decided to place the circles in an imaginary seating plan,
whereas others grouped them according to their status (e.g. all red
circles together, all green circles together and all orange circles
together). They also made some suggestions to improve the
visualisation of the achieved goals per student in the CD tool. For
example, to have columns made by tiles where each tile represents a
goal or surrounding the circles by an extra layer that gets filled in
parts based on the achieved goals.

Regarding the ST tool, teachers found it quite complicated and not
really useful in lessons. They claimed that it is hard to follow
through what each student did in this view and that they don’t think
they would be interested in all this information. They suggested
instead the idea of deriving a summary of students’ achievements based
on the timelines view. They also asked to be able to see their
students’ current models and rules via the ST tool in a similar way
they can via the CD tool.

Teachers expressed their fondness of the GA tool too and suggested
having all students visible on the screen. For example, instead of
having one long column in which case you need to scroll down to see
the rest of the class, having 2 (or more) columns placed next to each
other would be better to get an instant overview of the whole class’s
progress.

The second part of the formative evaluation was a focus group meeting
held with a group of pedagogical experts in maths education, to obtain
detailed feedback to inform the development of the final versions of
the TA tools, in preparation for summative evaluation in Phase D of
the project. The feedback resulting from this focus group meeting
comprised:

\begin{itemize}
\item Minor visual change requests relating to all three TA tools.
\item A recommendation that all information relating to `state’
  indicators to be turned off, by default, in the ST tool. 
\item The identification of a subset of indicators, comprising the
  most relevant indicators for use by the teacher during a lesson, to
  be displayed by default in the ST tool. 
\end{itemize}

All of the above changes were undertaken by the development team prior
to the summative evaluation of the TA tools. The subset of `important
indicators’ identified by the pedagogical experts are listed in
Section\ref{4.1}.




%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
